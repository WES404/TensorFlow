{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQBCpKj6ZKUg"
      },
      "source": [
        "# Natural Language Processing\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RNziiR7hrdl"
      },
      "source": [
        "Será usada Rede Neurais Recorrentes, aos quais são melhores para processar textos e carácteres. Faremos:\r\n",
        "\r\n",
        "\r\n",
        "1.   Geração de carácteres\r\n",
        "2.   Identificação de sentimento\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hGOmx7SieeJ"
      },
      "source": [
        "## Sequenciando os dados\r\n",
        "Diferente de imagens, Videos e textos precisam passar por um processo de \"adaptação\". Usaremos um dicionario para contar a frequência da palavra dentro do texto. Esse processo é chamado saco de palavras (bag of words). Para detectar sentimentos esse algoritimo não é muito eficaz já que ele não liga para a ordem das palavras.\r\n",
        "\r\n",
        "'''I thought the movie was going to be bad, but it was actually amazing!'''\r\n",
        "\r\n",
        "'''I thought the movie was going to be amazing, but it was actually bad!'''\r\n",
        "\r\n",
        "Essas duas frases terão o mesmo peso em certos algoritmos\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubNa2s_CjmsV"
      },
      "source": [
        "### Bag of Words\r\n",
        "\r\n",
        "A frequência da palavra é contada e colocada em um dicionário, com o index da palavra. Esse algoritmo não se preocupa com a ordem das palavras no texto.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jkY_pq6ZDn6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04532fc2-8188-4c40-cfc2-2e829228a016"
      },
      "source": [
        "vocabulario = {}  # mapeia a frequencia da palavra\r\n",
        "word_encoding = 1\r\n",
        "def bag_of_words(texto):\r\n",
        "  global word_encoding\r\n",
        "\r\n",
        "  palavras = texto.lower().split(\" \")  # divide todas as palavras do texto\r\n",
        "  bag = {}  # coloca todas as palavras e frequencia nesse dicionário \r\n",
        "\r\n",
        "  for palavra in palavras:\r\n",
        "    if palavra in vocabulario:\r\n",
        "      encoding = vocabulario[palavra]  # pega a frequencia da palavra\r\n",
        "    else:\r\n",
        "      vocabulario[palavra] = word_encoding\r\n",
        "      encoding = word_encoding\r\n",
        "      word_encoding += 1\r\n",
        "    \r\n",
        "    if encoding in bag:\r\n",
        "      bag[encoding] += 1\r\n",
        "    else:\r\n",
        "      bag[encoding] = 1\r\n",
        "  \r\n",
        "  return bag\r\n",
        "\r\n",
        "texto = \"this is a test to see if this test will work is is test a a\"\r\n",
        "bag = bag_of_words(texto)\r\n",
        "print(bag)\r\n",
        "print(vocabulario)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 2, 2: 3, 3: 3, 4: 3, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1}\n",
            "{'this': 1, 'is': 2, 'a': 3, 'test': 4, 'to': 5, 'see': 6, 'if': 7, 'will': 8, 'work': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5xPmP8_l0gj"
      },
      "source": [
        "Esse algoritmo não será utilizado, porque a frase perde a sequência."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HL5zu9HekzqY",
        "outputId": "26ebb7c3-c1a2-4e05-f269-5f79948ccfb5"
      },
      "source": [
        "positive_review = \"I thought the movie was going to be bad but it was actually amazing\"\r\n",
        "negative_review = \"I thought the movie was going to be amazing but it was actually bad\"\r\n",
        "\r\n",
        "pos_bag = bag_of_words(positive_review)\r\n",
        "neg_bag = bag_of_words(negative_review)\r\n",
        "\r\n",
        "print(\"Positive:\", pos_bag)\r\n",
        "print(\"Negative:\", neg_bag)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive: {10: 1, 11: 1, 12: 1, 13: 1, 14: 2, 15: 1, 5: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1, 21: 1}\n",
            "Negative: {10: 1, 11: 1, 12: 1, 13: 1, 14: 2, 15: 1, 5: 1, 16: 1, 21: 1, 18: 1, 19: 1, 20: 1, 17: 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twZuzFrSoN50"
      },
      "source": [
        "## Word Embedding\r\n",
        "Esse método transforma a palavra em um vetor, mantem a ordem e frequência e também aproxima palavras com significados próximos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFlDLd08tQis"
      },
      "source": [
        "## Recurrent Neural Networks (RNN's)\r\n",
        "\r\n",
        "Esse tipo de rede neural usa o valor anterior para calcular o novo.\r\n",
        "![alt text](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png)\r\n",
        "*Source: https://colah.github.io/posts/2015-08-Understanding-LSTMs/*\r\n",
        "\r\n",
        "Sendo:\r\n",
        "\r\n",
        "**h<sub>t</sub>** saida no tempo t\r\n",
        "\r\n",
        "**x<sub>t</sub>** entrada no tempo t\r\n",
        "\r\n",
        "**A** camada recorrente (loop)\r\n",
        "\r\n",
        "Por exemplo, um texto com t palavras será calculado uma palavra no H0 e será passado o calculo para H1, no qual a segunda palavra é calculada em cima do calculo da primeria e assim por diante.\r\n",
        "\r\n",
        "Esse método faz com que ao chegar no final(Ht) a primeira palavra seja perdida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTf7axJ7ugLO"
      },
      "source": [
        "## LSTM - Long-Short Term Memory\r\n",
        "\r\n",
        "O RNN anterior é chamado de simples. O LSTM usa um método para acessar os valores anteriores da camada que desaparecem no RNN simples ao longo do calculo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOBxCcPcUBp9"
      },
      "source": [
        "## Análise de Sentimentos\r\n",
        "\r\n",
        "Usando textos, o algoritmo classificará opiniões como boas, ruins ou neutras em relaçao a filmes.\r\n",
        "\r\n",
        "## Database de Reviews de Filmes\r\n",
        "\r\n",
        "Utilizando Keras, um dataset com 25.000 reviews do IMDB já processado e com labels será utilizado. Cada review já estava codificado com a frequência da palavra no dataset inteiro."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBk9S6fDuSMt"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRTP1wMxl-y6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e142d016-26a5-40cf-fb82-b9ce9076a6c0"
      },
      "source": [
        "%tensorflow_version 2.x  # this line is not required unless you are in a notebook\r\n",
        "from keras.datasets import imdb\r\n",
        "from keras.preprocessing import sequence\r\n",
        "import keras\r\n",
        "import tensorflow as tf\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "VOCAB_TAM = 88584\r\n",
        "\r\n",
        "MAXLEN = 250\r\n",
        "BATCH_SIZE = 64\r\n",
        "\r\n",
        "(treino_X, treino_y), (teste_X, teste_y) = imdb.load_data(num_words = VOCAB_TAM)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `2.x  # this line is not required unless you are in a notebook`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z15gusnkYOtE"
      },
      "source": [
        "## Mais porcessamento\r\n",
        "\r\n",
        "Como cama review não tem um valor fixo, vamos colocar todos com 250 itens.\r\n",
        "\r\n",
        "Se for maior que 250 descartamos o restante.\r\n",
        "Se for menor que 250 acrescentamos o restante com 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJRgCq76YBxO"
      },
      "source": [
        "treino_X = sequence.pad_sequences(treino_X, MAXLEN)\r\n",
        "teste_X = sequence.pad_sequences(teste_X, MAXLEN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaRDH_pVZdul"
      },
      "source": [
        "## Modelo\r\n",
        "\r\n",
        "Usamos um embedding de palavras como entrada, um LSTM como camada escondida e de saída usamo uma densa. O 32 é o número de dimensões do vetor. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcR7NMHNY-8t"
      },
      "source": [
        "modelo = tf.keras.Sequential([\r\n",
        "    tf.keras.layers.Embedding(VOCAB_TAM, 32),\r\n",
        "    tf.keras.layers.LSTM(32),\r\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7Gyw9eLZ_PD"
      },
      "source": [
        "## Treino\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJs6SuQwZ67L",
        "outputId": "d99221bb-0df5-49da-a32f-8b7dbcff8169"
      },
      "source": [
        "modelo.compile(loss=\"binary_crossentropy\",optimizer=\"rmsprop\",metrics=['acc'])\r\n",
        "\r\n",
        "history = modelo.fit(treino_X, treino_y, epochs=10, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 45s 20ms/step - loss: 0.5195 - acc: 0.7284 - val_loss: 0.2891 - val_acc: 0.8854\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 12s 19ms/step - loss: 0.2338 - acc: 0.9129 - val_loss: 0.2797 - val_acc: 0.8882\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 12s 19ms/step - loss: 0.1708 - acc: 0.9376 - val_loss: 0.2648 - val_acc: 0.8900\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 12s 19ms/step - loss: 0.1446 - acc: 0.9495 - val_loss: 0.2989 - val_acc: 0.8916\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 12s 19ms/step - loss: 0.1165 - acc: 0.9619 - val_loss: 0.3553 - val_acc: 0.8802\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 12s 19ms/step - loss: 0.1032 - acc: 0.9634 - val_loss: 0.3288 - val_acc: 0.8808\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 12s 19ms/step - loss: 0.0919 - acc: 0.9710 - val_loss: 0.3944 - val_acc: 0.8784\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 12s 19ms/step - loss: 0.0768 - acc: 0.9745 - val_loss: 0.4259 - val_acc: 0.8756\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 12s 19ms/step - loss: 0.0655 - acc: 0.9788 - val_loss: 0.3372 - val_acc: 0.8874\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 12s 19ms/step - loss: 0.0579 - acc: 0.9813 - val_loss: 0.4093 - val_acc: 0.8734\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KT3hNEUdaLAa",
        "outputId": "78dd7bd5-5aa7-4045-d0cc-dcb052435668"
      },
      "source": [
        "results = modelo.evaluate(teste_X, teste_y)\r\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 4s 5ms/step - loss: 0.5369 - acc: 0.8345\n",
            "[0.5369390845298767, 0.8344799876213074]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZOWMl9ieRzA"
      },
      "source": [
        "O modelo acertou 83,44% dos testes.\r\n",
        "\r\n",
        "# Predição\r\n",
        "\r\n",
        "Como o modelo tá codificado, para prever novos exemplos precisamos codificar o texto também.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atXWMYhobQ8W",
        "outputId": "d4ea724e-0f38-45cb-ccbb-69fb696ca3f1"
      },
      "source": [
        "index_palavras = imdb.get_word_index() # Index das palavras provenientes do IMDB\r\n",
        "\r\n",
        "def encode_text(texto):\r\n",
        "  tokens = keras.preprocessing.text.text_to_word_sequence(texto)\r\n",
        "  tokens = [index_palavras[palavra] if palavra in index_palavras else 0 for palavra in tokens] \r\n",
        "  # Se a palavra estiver no dicionario ela é add ao Token\r\n",
        "  return sequence.pad_sequences([tokens], MAXLEN)[0] # Como é uma sequencia de listas, pegamos só a primeira\r\n",
        "\r\n",
        "text = \"that movie was just amazing, so amazing\"\r\n",
        "encoded = encode_text(text)\r\n",
        "print(encoded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0  12  17  13  40 477  35 477]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjsMCCx0fW_4",
        "outputId": "61cf7b11-498c-4fcb-a76b-f6ea0e947411"
      },
      "source": [
        "# Decodifica os valores para texto\r\n",
        "\r\n",
        "index_palavras_reverso = {value: key for (key, value) in index_palavras.items()}\r\n",
        "\r\n",
        "def decode_integers(integers):\r\n",
        "    texto = \"\"\r\n",
        "    for num in integers:\r\n",
        "      if num != 0:\r\n",
        "        texto += index_palavras_reverso[num] + \" \"\r\n",
        "\r\n",
        "    return texto[:-1]\r\n",
        "  \r\n",
        "print(decode_integers(encoded))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "that movie was just amazing so amazing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6X37mKo8fzLJ",
        "outputId": "8cf8f1ac-15bb-461c-dbf6-4d57aaf195ed"
      },
      "source": [
        "# Prevendo\r\n",
        "\r\n",
        "def predict(texto):\r\n",
        "  texto_codificado = encode_text(texto)\r\n",
        "  pred = np.zeros((1,250))\r\n",
        "  pred[0] = texto_codificado\r\n",
        "  resultado = modelo.predict(pred) \r\n",
        "  print(resultado[0])\r\n",
        "\r\n",
        "positive_review = \"That movie was! really loved it and would great watch it again because it was amazingly great\"\r\n",
        "predict(positive_review)\r\n",
        "\r\n",
        "negative_review = \"that movie really sucked. I hated it and wouldn't watch it again. Was one of the worst things I've ever watched\"\r\n",
        "predict(negative_review)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.89084]\n",
            "[0.08708591]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t--_EsXVkarz"
      },
      "source": [
        "# Gerador de Peças\r\n",
        "\r\n",
        "Mostrando uma peça de teatro ao RNN, faremos ele criar uma versão nova em cima do exemplo.\r\n",
        "\r\n",
        "# Dataset\r\n",
        "\r\n",
        "Usaremos Romeo e Julieta de Shakesphere, mas também podemos usar outro arquivo TXT prórpio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbf6bVxEgGMq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5c622d8-e467-4362-b213-7648ec452acb"
      },
      "source": [
        "caminho = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c3dizz7lBEG"
      },
      "source": [
        "### Arquivo proprio em TXT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3s67p_alFyt"
      },
      "source": [
        "from google.colab import files\r\n",
        "path_to_file = list(files.upload().keys())[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "er5lZXR4lOTY"
      },
      "source": [
        "## Lendo o Conteúdo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHYzpwpQlecj",
        "outputId": "5b2eed94-88a4-40d2-d331-96d8a12e4e8a"
      },
      "source": [
        "# Lê e decodifica para py2 compat.\r\n",
        "texto = open(caminho, 'rb').read().decode(encoding='utf-8')\r\n",
        "# tamanho do texto é o número de caracteres estão nele\r\n",
        "print ('Tamanho do texto: {} caracteres'.format(len(texto)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tamanho do texto: 1115394 caracteres\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cbQhqQAlSL-"
      },
      "source": [
        "## Codificando\r\n",
        "\r\n",
        "Faremos a codificação tirando caracteres unicos do texto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIccToAFl-nx"
      },
      "source": [
        "vocabulario = sorted(set(texto))\r\n",
        "# Cria um mapa para caracteres unicos por indices.\r\n",
        "caract_para_indx = {u:i for i, u in enumerate(vocabulario)}\r\n",
        "indx_para_caract = np.array(vocabulario)\r\n",
        "\r\n",
        "def text_to_int(text):\r\n",
        "  return np.array([caract_para_indx[c] for c in texto])\r\n",
        "\r\n",
        "texto_como_int = text_to_int(texto)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpZghXMylLeT",
        "outputId": "63a07828-4b10-4892-a4a4-eafb2c2acff9"
      },
      "source": [
        "print(\"Texto:\", texto[:13])\r\n",
        "print(\"codificado:\", text_to_int(texto[:13]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto: First Citizen\n",
            "codificado: [18 47 56 ... 45  8  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xo_GESxEmpK9",
        "outputId": "f8682c80-d708-45e8-9621-ca57a624cfaf"
      },
      "source": [
        "# Converte de indeces para texto\r\n",
        "\r\n",
        "def int_to_text(ints):\r\n",
        "  try:\r\n",
        "    ints = ints.numpy()\r\n",
        "  except:\r\n",
        "    pass\r\n",
        "  return ''.join(indx_para_caract[ints])\r\n",
        "\r\n",
        "print(int_to_text(texto_como_int[:13]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faKNvcX1m9kQ"
      },
      "source": [
        "## Criando exemplos de treino\r\n",
        "\r\n",
        "Como o objetivo é criar uma nova peça, para o algoritmo gerar novos texto passaremos exemplos em que ele deve completar uma palavra ou frase.\r\n",
        "\r\n",
        "Os exemplos de treino usaram uma sequência definada de caracteres que serviram de entra e de saida, mas com a saída a 1 caractere a direita. Exemplo:\r\n",
        "\r\n",
        "*input: Hell | output: ello*\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehdIXbjTm0KF"
      },
      "source": [
        "seq_length = 100  # tamanho da sequencia para treino\r\n",
        "examplos_por_epoch = len(text)//(seq_length+1)\r\n",
        "\r\n",
        "# Cria exemplos de treino / alvos\r\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(texto_como_int)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_XGGTm_oS2b"
      },
      "source": [
        "Agora usamos o método de Batch para transforma esse dataset em batchs de qualquer tamanho"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWGrRB1ZoQ3B"
      },
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYBwJvBcoh79"
      },
      "source": [
        "def split_input_target(chunk):  # para o exemplo: hello\r\n",
        "    input_texto = chunk[:-1]  # hell\r\n",
        "    target_texto = chunk[1:]  # ello\r\n",
        "    return input_texto, target_texto  # hell, ello\r\n",
        "\r\n",
        "dataset = sequences.map(split_input_target)  # Usamo o mapa para aplicar a função a todas as entradas de dados"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWBvinxno6j9",
        "outputId": "88f50dd8-7037-4079-bf70-f35a13cedcaa"
      },
      "source": [
        "for x, y in dataset.take(2):\r\n",
        "  print(\"\\n\\nEXEMPLO\\n\")\r\n",
        "  print(\"INPUT\")\r\n",
        "  print(int_to_text(x))\r\n",
        "  print(\"\\nOUTPUT\")\r\n",
        "  print(int_to_text(y))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "EXEMPLO\n",
            "\n",
            "INPUT\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n",
            "\n",
            "OUTPUT\n",
            "irst Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You \n",
            "\n",
            "\n",
            "EXEMPLO\n",
            "\n",
            "INPUT\n",
            "are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you \n",
            "\n",
            "OUTPUT\n",
            "re all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eIWecrnpJF6"
      },
      "source": [
        "Finalmente construimos batches de treino"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhkNgbRco9v9"
      },
      "source": [
        "BATCH_SIZE = 64\r\n",
        "VOCAB_SIZE = len(vocabulario)  # vocab é o número de caracteres unicos\r\n",
        "EMBEDDING_DIM = 256\r\n",
        "RNN_UNITS = 1024\r\n",
        "\r\n",
        "# Buffer size é para embaralhar o dataset\r\n",
        "# (TF data is designed to work with possibly infinite sequences,\r\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\r\n",
        "# it maintains a buffer in which it shuffles elements).\r\n",
        "BUFFER_SIZE = 10000\r\n",
        "\r\n",
        "data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPA4HCbBpb3t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}