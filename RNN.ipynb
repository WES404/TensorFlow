{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQBCpKj6ZKUg"
      },
      "source": [
        "# Natural Language Processing\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RNziiR7hrdl"
      },
      "source": [
        "Será usada Rede Neurais Recorrentes, aos quais são melhores para processar textos e carácteres. Faremos:\r\n",
        "\r\n",
        "\r\n",
        "1.   Geração de carácteres\r\n",
        "2.   Identificação de sentimento\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hGOmx7SieeJ"
      },
      "source": [
        "## Sequenciando os dados\r\n",
        "Diferente de imagens, Videos e textos precisam passar por um processo de \"adaptação\". Usaremos um dicionario para contar a frequência da palavra dentro do texto. Esse processo é chamado saco de palavras (bag of words). Para detectar sentimentos esse algoritimo não é muito eficaz já que ele não liga para a ordem das palavras.\r\n",
        "\r\n",
        "'''I thought the movie was going to be bad, but it was actually amazing!'''\r\n",
        "\r\n",
        "'''I thought the movie was going to be amazing, but it was actually bad!'''\r\n",
        "\r\n",
        "Essas duas frases terão o mesmo peso em certos algoritmos\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubNa2s_CjmsV"
      },
      "source": [
        "### Bag of Words\r\n",
        "\r\n",
        "A frequência da palavra é contada e colocada em um dicionário, com o index da palavra. Esse algoritmo não se preocupa com a ordem das palavras no texto.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jkY_pq6ZDn6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04532fc2-8188-4c40-cfc2-2e829228a016"
      },
      "source": [
        "vocabulario = {}  # mapeia a frequencia da palavra\r\n",
        "word_encoding = 1\r\n",
        "def bag_of_words(texto):\r\n",
        "  global word_encoding\r\n",
        "\r\n",
        "  palavras = texto.lower().split(\" \")  # divide todas as palavras do texto\r\n",
        "  bag = {}  # coloca todas as palavras e frequencia nesse dicionário \r\n",
        "\r\n",
        "  for palavra in palavras:\r\n",
        "    if palavra in vocabulario:\r\n",
        "      encoding = vocabulario[palavra]  # pega a frequencia da palavra\r\n",
        "    else:\r\n",
        "      vocabulario[palavra] = word_encoding\r\n",
        "      encoding = word_encoding\r\n",
        "      word_encoding += 1\r\n",
        "    \r\n",
        "    if encoding in bag:\r\n",
        "      bag[encoding] += 1\r\n",
        "    else:\r\n",
        "      bag[encoding] = 1\r\n",
        "  \r\n",
        "  return bag\r\n",
        "\r\n",
        "texto = \"this is a test to see if this test will work is is test a a\"\r\n",
        "bag = bag_of_words(texto)\r\n",
        "print(bag)\r\n",
        "print(vocabulario)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 2, 2: 3, 3: 3, 4: 3, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1}\n",
            "{'this': 1, 'is': 2, 'a': 3, 'test': 4, 'to': 5, 'see': 6, 'if': 7, 'will': 8, 'work': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5xPmP8_l0gj"
      },
      "source": [
        "Esse algoritmo não será utilizado, porque a frase perde a sequência."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HL5zu9HekzqY",
        "outputId": "26ebb7c3-c1a2-4e05-f269-5f79948ccfb5"
      },
      "source": [
        "positive_review = \"I thought the movie was going to be bad but it was actually amazing\"\r\n",
        "negative_review = \"I thought the movie was going to be amazing but it was actually bad\"\r\n",
        "\r\n",
        "pos_bag = bag_of_words(positive_review)\r\n",
        "neg_bag = bag_of_words(negative_review)\r\n",
        "\r\n",
        "print(\"Positive:\", pos_bag)\r\n",
        "print(\"Negative:\", neg_bag)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive: {10: 1, 11: 1, 12: 1, 13: 1, 14: 2, 15: 1, 5: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1, 21: 1}\n",
            "Negative: {10: 1, 11: 1, 12: 1, 13: 1, 14: 2, 15: 1, 5: 1, 16: 1, 21: 1, 18: 1, 19: 1, 20: 1, 17: 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twZuzFrSoN50"
      },
      "source": [
        "## Word Embedding\r\n",
        "Esse método transforma a palavra em um vetor, mantem a ordem e frequência e também aproxima palavras com significados próximos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFlDLd08tQis"
      },
      "source": [
        "## Recurrent Neural Networks (RNN's)\r\n",
        "\r\n",
        "Esse tipo de rede neural usa o valor anterior para calcular o novo.\r\n",
        "![alt text](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png)\r\n",
        "*Source: https://colah.github.io/posts/2015-08-Understanding-LSTMs/*\r\n",
        "\r\n",
        "Sendo:\r\n",
        "\r\n",
        "**h<sub>t</sub>** saida no tempo t\r\n",
        "\r\n",
        "**x<sub>t</sub>** entrada no tempo t\r\n",
        "\r\n",
        "**A** camada recorrente (loop)\r\n",
        "\r\n",
        "Por exemplo, um texto com t palavras será calculado uma palavra no H0 e será passado o calculo para H1, no qual a segunda palavra é calculada em cima do calculo da primeria e assim por diante.\r\n",
        "\r\n",
        "Esse método faz com que ao chegar no final(Ht) a primeira palavra seja perdida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTf7axJ7ugLO"
      },
      "source": [
        "## LSTM - Long-Short Term Memory\r\n",
        "\r\n",
        "O RNN anterior é chamado de simples. O LSTM usa um método para acessar os valores anteriores da camada que desaparecem no RNN simples ao longo do calculo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBk9S6fDuSMt"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRTP1wMxl-y6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}